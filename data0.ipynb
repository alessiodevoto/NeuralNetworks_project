{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1x4bI5GDkQ4AWe49lkdSR0S7Mdhe1eSYO",
      "authorship_tag": "ABX9TyOrv0vYnowJ5XSaEIbXuum8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessiodevoto/NeuralNetworks_project/blob/main/data0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vbqCsi3bv9a"
      },
      "source": [
        "# Libraries and framework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3c_9Uu1C-4C",
        "outputId": "e809de00-6756-4d7a-e350-18436690ca8b"
      },
      "source": [
        "!python -c \"import torch; print(torch.__version__)\"\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-geometric\n",
        "!pip install wget\n",
        "!pip install pickle5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu102\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu102/torch_scatter-2.0.8-cp37-cp37m-linux_x86_64.whl (8.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 6.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.8\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu102/torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.12\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.1.tar.gz (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.0.1-py3-none-any.whl (379 kB)\n",
            "\u001b[K     |████████████████████████████████| 379 kB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.1-py3-none-any.whl size=513822 sha256=84d0513dbd828b3b3674eeb0f9917aee2c31307f9cf246dfedbfe3a3e1939edf\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/3d/42/20589db73c66b5109fb93a0c5743edfd6ab5ca820a52afacfc\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 rdflib-6.0.1 torch-geometric-2.0.1 yacs-0.1.8\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=3f86912a1d7c6d170581442a85f48fabef33416a3be0d1e26efc7b88b3799e85\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 8.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp37-cp37m-linux_x86_64.whl size=219315 sha256=fddee8e33f2d7f54968d60f9896b27d2eaa2822fb3ecb1304dccbe9d19238ff8\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/6a/00/67136a90d6aca437d806d1d3cedf98106e840c97a3e5188198\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKxM2EDhSAmq",
        "outputId": "8e92ef9a-4d05-4142-f8ca-5562c61973e0"
      },
      "source": [
        "cd /content/drive/MyDrive/gcn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/gcn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKx5CnvUDc-3"
      },
      "source": [
        "# Dataset\n",
        "The PylonsDataset class builds up a dataset of graph, one for each photo in data. Download options are: \n",
        "- complete_data : downloads json files (raw) and pyG dataset (processed)\n",
        "- processed_data : only downloads processed data in PyG format\n",
        "- raw_data: only downloads json files, and processes them to create a PyG dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WghsvnpNFKM4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cdf3f8d-cff1-4896-e3f0-ae8a18a914b3"
      },
      "source": [
        "from PylonsDataset import PylonsDataset\n",
        "mydata = PylonsDataset(root='data', password='matching', download_option='raw_data')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset to data ...\n",
            "Downloading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving information about relations between assets...\n",
            "One-hot encoding assets...\n",
            "Processing dictionaries...\n",
            "Processing datasets in json format...\n",
            "Parsing dataset file: data/raw/datasets/D110-36742.json\n",
            "Parsing dataset file: data/raw/datasets/D550-19031.json\n",
            "Parsing dataset file: data/raw/datasets/D340-33954.json\n",
            "Parsing dataset file: data/raw/datasets/D260-26837.json\n",
            "Parsing dataset file: data/raw/datasets/D550-47654.json\n",
            "Parsing dataset file: data/raw/datasets/D110-11881.json\n",
            "Parsing dataset file: data/raw/datasets/D340-49418.json\n",
            "Parsing dataset file: data/raw/datasets/D260-49027.json\n",
            "Number of elements not included (unclassifiable photos): 789\n",
            "Number of elements in dataset: 9444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ready\n",
            "Find raw data in data/raw and processed data in data/processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78SoJ7AfEcOK"
      },
      "source": [
        " In order to get a single graph, we use __get()__, whereas to get a pair of graphs randomly generated on the fly, we use ____getitem__()__.\n",
        " A single graph, stored as an object of the class Data , has the following features:\n",
        " - x : feature matrix NxF, N num nodes, F num features\n",
        " - edge_index: graph connectivity in PyG format\n",
        " - edge_attr: edge features  \n",
        " - y: target value, i.e. id of pylons captured in this graph\n",
        " - photo_id: id of photo this graph represents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfzn_WZbImeK",
        "outputId": "5aff7e22-c364-43e9-db98-127e0403e9ef"
      },
      "source": [
        "g0 = mydata.get(0)\n",
        "print('Graph element at index 0:')\n",
        "print(g0)\n",
        "print('\\n\\nFeatures matrix of graph element at index 0:')\n",
        "print(g0.x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph element at index 0:\n",
            "Data(x=[3, 52], edge_index=[2, 12], edge_attr=[12, 1], y='504631_4353907_57', photo_id='F_2020_06_23@15.58.44(612)_Converted_CROP_1_73.jpg')\n",
            "\n",
            "\n",
            "Features matrix of graph element at index 0:\n",
            "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.6752, 0.9000, 6.7219],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.1000, 7.9195],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.5606, 0.9000, 0.0095]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04pM1KQZLNrl"
      },
      "source": [
        "We can also get a pair of graph, together with a label (1:similar, -1: not similar). \n",
        "Pairs of graph are saved in a PairData structure, derived from data, optimized for batching. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO0zbdk8LXDe",
        "outputId": "dee88d94-d5f1-4b9b-8ab7-a0dac1a20dd5"
      },
      "source": [
        "pair = mydata[10] # equivalent to mydata.__geitem__(0)\n",
        "print(pair)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PairData(x1=[9, 52], edge_index1=[2, 90], edge_attr1=[90, 1], y1='504708_4353863_31', x2=[8, 52], edge_index2=[2, 72], edge_attr2=[72, 1], y2='504708_4353863_31', target=[1], num_nodes=17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS_rONOJZuQw"
      },
      "source": [
        "We can explore some properies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGc5rkzbZyQi",
        "outputId": "55903887-cce0-4218-a499-7249bbd7bedc"
      },
      "source": [
        "print(f'Number of node features: {mydata.num_node_features}')\n",
        "print(f'Number of edge features: {mydata.num_edge_features}')\n",
        "print(f'Average number of nodes per graph: {mydata.avg_nodes_per_graph}')\n",
        "print(f'Average number of edges per graph: {mydata.avg_edges_per_graph}')\n",
        "print(f'Dataset is undirected: {mydata.is_undirected}')\n",
        "print(f'Number of classes (i.e. of captured pylons): {mydata.num_classes}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of node features: 52\n",
            "Number of edge features: 1\n",
            "Average number of nodes per graph: 6.0630029648454045\n",
            "Average number of edges per graph: 49.32570944515036\n",
            "Dataset is undirected: True\n",
            "Number of classes (i.e. of captured pylons): 1965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_mu0pDTWjd6"
      },
      "source": [
        "Whether the pair of graph are similar or not and which specific pair to extract is decided randomly on the fly when we invoke __getitem__. In order to achieve a deterministic behavior, we can create a dataset with the option `deterministic = True` or just set the property to `True`. This way, the similarity is based on the index (even->similar, odd->not similar)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk8sDXn3XImQ",
        "outputId": "f5e5b8b4-4c8b-44b7-ec3f-8a038158cf27"
      },
      "source": [
        "print('Randomly extracted pairs:')\n",
        "print(mydata[10])\n",
        "print(mydata[10])\n",
        "print(mydata[10])\n",
        "print('Deterministically extracted pairs:')\n",
        "mydata.deterministc = False\n",
        "print(mydata[10])\n",
        "print(mydata[10])\n",
        "print(mydata[10])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Randomly extracted pairs:\n",
            "PairData(x1=[9, 52], edge_index1=[2, 90], edge_attr1=[90, 1], y1='504708_4353863_31', x2=[17, 52], edge_index2=[2, 306], edge_attr2=[306, 1], y2='327131_5146905_156', target=[1], num_nodes=26)\n",
            "PairData(x1=[9, 52], edge_index1=[2, 90], edge_attr1=[90, 1], y1='504708_4353863_31', x2=[10, 52], edge_index2=[2, 110], edge_attr2=[110, 1], y2='504708_4353863_31', target=[1], num_nodes=19)\n",
            "PairData(x1=[9, 52], edge_index1=[2, 90], edge_attr1=[90, 1], y1='504708_4353863_31', x2=[8, 52], edge_index2=[2, 72], edge_attr2=[72, 1], y2='504708_4353863_31', target=[1], num_nodes=17)\n",
            "Deterministically extracted pairs:\n",
            "PairData(x1=[9, 52], edge_index1=[2, 90], edge_attr1=[90, 1], y1='504708_4353863_31', x2=[10, 52], edge_index2=[2, 110], edge_attr2=[110, 1], y2='504708_4353863_31', target=[1], num_nodes=19)\n",
            "PairData(x1=[9, 52], edge_index1=[2, 90], edge_attr1=[90, 1], y1='504708_4353863_31', x2=[10, 52], edge_index2=[2, 110], edge_attr2=[110, 1], y2='504708_4353863_31', target=[1], num_nodes=19)\n",
            "PairData(x1=[9, 52], edge_index1=[2, 90], edge_attr1=[90, 1], y1='504708_4353863_31', x2=[8, 52], edge_index2=[2, 72], edge_attr2=[72, 1], y2='504708_4353863_31', target=[1], num_nodes=17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1Quh6-PbmEP"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpOo5sxOQ6dY",
        "outputId": "d34f951c-a5c1-40c1-b6af-2c46bab05fcc"
      },
      "source": [
        "from model import GraphEmbeddingNet\n",
        "from loss import PairwiseLoss\n",
        "from PylonsDataset import PylonsDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "import torch\n",
        "\n",
        "dev = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(dev)  \n",
        "\n",
        "model = GraphEmbeddingNet(\n",
        "    conv_hidden_channels=[64, 64, 64], \n",
        "    graph_aggr_dim=32,\n",
        "    node_feature_dim=52,\n",
        "    edge_feature_dim=1,\n",
        "    node_hidden_sizes=[52, 52],\n",
        "    edge_hidden_sizes=None\n",
        ")\n",
        "print(model)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = PairwiseLoss()\n",
        "EPOCHS = 50\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GraphEmbeddingNet(\n",
            "  (graph_encoder): GraphEncoder(\n",
            "    (MLP1): Sequential(\n",
            "      (0): Linear(in_features=53, out_features=53, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=53, out_features=53, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (message_net): MessageNet(\n",
            "    (conv1): GCNConv(53, 64)\n",
            "    (conv2): GCNConv(64, 64)\n",
            "    (conv3): GCNConv(64, 64)\n",
            "  )\n",
            "  (aggregator): GraphAggregator(\n",
            "    (aggregator): Linear(in_features=64, out_features=96, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0UJ17UGSX2O"
      },
      "source": [
        "print('Starting training')\n",
        "for epoch in range(1, EPOCHS):\n",
        "    model.train()\n",
        "    loss = None\n",
        "    losses = []\n",
        "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "        # print('[FORWARD] processing values:')\n",
        "        # print(data.x1)\n",
        "        # print(data.x2)\n",
        "        # print(data.x1_batch)\n",
        "        # print(data.x2_batch)\n",
        "        # print(data.num_graphs)\n",
        "        emb1, emb2 = model(data)\n",
        "        #emb1 = linear_layer(data.x1)\n",
        "        #emb1 = conv_layer(emb1, data.edge_index1)\n",
        "        #print('[FORWARD] processed values:')\n",
        "        #print(emb1)\n",
        "        #print(emb2)\n",
        "        loss = criterion(emb1, emb2, data.target)  # Compute the loss.\n",
        "        #print('[FORWARD] loss:')\n",
        "        #print(loss.size())\n",
        "        losses.append(loss)\n",
        "        loss.backward(torch.ones_like(loss))  # Derive gradients.\n",
        "        optimizer.step()  # Update parameters based on gradients.\n",
        "        optimizer.zero_grad()  # Clear gradients.\n",
        "        #print(f'[FORWARD] List of losses in this batch: size:{len(losses)} list: {losses}')\n",
        "        #print(f'[FORWARD] Avg loss in this batch: {losses[-1].mean}')\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {torch.cat(losses, 1).mean()}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}